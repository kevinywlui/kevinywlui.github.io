
# 5.1/5.2 - Determinants

Let $T:\mathbb{R}^n\to\mathbb{R}^n$ be a linear transform and $A$ be the square matrix defined so that $T(x)=Ax$. Then the absolute value of the determinant of $A$, denoted det($A$), measures the change in volume under $T$. This means that if $S$ is a shape of volume V then $T(S)=\{T(s):s\in \mathbb{R}^n\}$ has volume $|\det(A)|$V.

**Definition:** For any $n\in \mathbb{N}$, The **determinant** is the unique function from the set of square matrices of size $n$ so the real numbers with the following 3 properties:

* $\det(I_n)=1$,
* When viewing a square matrices as a list of $n$ column vectors, the determinant is $n$-linear. This means $\det([a_1,\ldots,ca_i+db_i,\ldots,a_n])=c\det([a_1,\ldots,a_i,\ldots,a_n])+d\det([a_1,\ldots,b_i,\ldots,a_n])$.
* If this there is a column of zero, then the determinant is zero.

The determinant of a linear transform $T:\mathbb{R}^n\to\mathbb{R}^n$ is the determinant of its associated matrix.

**Properties:**

* $\det(AB)=\det(A)\det(B)$,
* $\det(A^t)=\det(A)$,
* If $A$ is upper (or lower) triangular, then $\det(A)$ is the product of the diagonal,
* $\det(cA)=c^n\det(A)$,
* If $A$ has positive nullity, then $\det(A)=0$.

**Computation:** There is a thing called cofactor expansion. It is terrible but we will learn it. In practice, another method is used like $LU$-decomposition. There $LU$ decompositon of a matrix $A$ is $A=LU$ where $L$ is lower trianguluar and $U$ is upper triangular. Then $\det(A)=\det(L)\det(U)$, where $\det(L)$ and $\det(U)$ is the product of the diagonal. Give $n=2$ and $n=3$ shortcuts and the general cofactor formula. Note that you can expand along any row or column.

**Notation:** Often you denote the determinant of a matrix by replacing the square brackets by straight lines.

**Examples:** Compute the determinant in the following cases:

* $T(x,y)=(x+y,y)$
* $T(x,y)=(3x+y,-y)$. Also what is the determinant of $T^{-1}$ here?
* Here is a $3\times 3$ example
* Here is a $4\times 4$ example that I won't actually work out fully

**Theorem:** Let $S=\{a_1,\ldots,a_n\}$ be a set of vectors in $\mathbb{R}^n$, let $A=[a_1\; \ldots \; a_n]$ and $T:\mathbb{R}^n\to\mathbb{R}^n$ be given by $T(x)=Ax$. Then the following are equivalent:

* $S$ spans $\mathbb{R}^n$,
* $S$ is linearly independent,
* $S$ is a basis for $\mathbb{R}^n$,
* $Ax=b$ has a unique solution for every $b\in \mathbb{R}^n$,
* $T$ is onto,
* $T$ is one-to-one,
* $\ker T=\{0\}$,
* $range(T)=\mathbb{R}^n$,
* $col(A)=\mathbb{R}^n$,
* $row(A)=\mathbb{R}^n$,
* $rank(A)=n$,
* $nullity(A)=0$,
* Any echelon form of $A$ has no zero entries on the diagonal,
* The reduced echelon form of $A$ is the identity matrix,
* $\det(A)\neq 0$,
