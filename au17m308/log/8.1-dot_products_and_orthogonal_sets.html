<h1 id="dot-products-and-orthogonal-sets">8.1 Dot Products and Orthogonal Sets</h1>
<p><strong>Definition:</strong> Suppose that <span class="math inline"><em>u</em> = (<em>u</em><sub>1</sub>, …, <em>u</em><sub><em>n</em></sub>)</span> and <span class="math inline"><em>v</em> = (<em>v</em><sub>1</sub>, …, <em>v</em><sub><em>n</em></sub>)</span> are both vectors in <span class="math inline">ℝ<sup><em>n</em></sup></span>. Then the <em>dot product</em> of <span class="math inline"><em>u</em></span> and <span class="math inline"><em>v</em></span> is <span class="math inline"><em>u</em> ⋅ <em>v</em> = <em>u</em><sub>1</sub><em>v</em><sub>1</sub> + … + <em>u</em><sub><em>n</em></sub><em>v</em><sub><em>n</em></sub></span>.</p>
<p><strong>Theorem:</strong> Let <span class="math inline"><em>u</em>, <em>v</em>, <em>w</em></span> be in <span class="math inline">ℝ<sup><em>n</em></sup></span>. Then the dot product has the following properties:</p>
<ul>
<li>(Symmetry) <span class="math inline"><em>u</em> ⋅ <em>v</em> = <em>v</em> ⋅ <em>u</em></span>,</li>
<li>(Linearity) <span class="math inline">(<em>c</em><em>u</em> + <em>v</em>) ⋅ <em>w</em> = <em>c</em><em>u</em> ⋅ <em>w</em> + <em>v</em> ⋅ <em>w</em></span>,</li>
<li>(Positive Definite) <span class="math inline"><em>u</em> ⋅ <em>u</em> ≥ 0</span> for all <span class="math inline"><em>u</em></span>, and <span class="math inline"><em>u</em> ⋅ <em>u</em> = 0</span> if and and only if <span class="math inline"><em>u</em> = 0</span>.</li>
</ul>
<p><strong>Definition:</strong> Let <span class="math inline"><em>x</em></span> be a vector in <span class="math inline">ℝ<sup><em>n</em></sup></span>, then the <em>norm</em> of <span class="math inline"><em>x</em></span> is given by <span class="math inline">$\|x\|=\sqrt{x\cdot x}$</span>. Note that <span class="math inline">∥<em>c</em><em>x</em>∥ = |<em>c</em>|∥<em>x</em>∥</span>.</p>
<p>For two vectors <span class="math inline"><em>u</em></span> and <span class="math inline"><em>v</em></span>, the <em>distance</em> between <span class="math inline"><em>u</em></span> and <span class="math inline"><em>v</em></span> is given by <span class="math inline">∥<em>u</em> − <em>v</em>∥</span>.</p>
<p><strong>Definition:</strong> Let <span class="math inline"><em>u</em></span> and <span class="math inline"><em>v</em></span> be vectors in <span class="math inline">ℝ<sup><em>n</em></sup></span> are <em>orthogonal</em> if <span class="math inline"><em>u</em> ⋅ <em>v</em> = 0</span>.</p>
<p><strong>Theorem:</strong> (Pythagorean Theorem) Suppose that <span class="math inline"><em>u</em></span> and <span class="math inline"><em>v</em></span> are in <span class="math inline">ℝ<sup><em>n</em></sup></span>. Then <span class="math inline">∥<em>u</em> + <em>v</em>∥<sup>2</sup> = ∥<em>u</em>∥<sup>2</sup> + ∥<em>v</em>∥<sup>2</sup></span> if and only if <span class="math inline"><em>u</em> ⋅ <em>v</em> = 0</span>.</p>
<p><strong>Theorem:</strong> (Triangle Inequality) If <span class="math inline"><em>u</em></span> and <span class="math inline"><em>v</em></span> are in <span class="math inline">ℝ<sup><em>n</em></sup></span>, then <span class="math inline">∥<em>u</em> + <em>v</em>∥ ≤ ∥<em>u</em>∥ + ∥<em>v</em>∥</span>.</p>
<p><strong>Definition:</strong> Let <span class="math inline"><em>S</em></span> be a subspace of <span class="math inline">ℝ<sup><em>n</em></sup></span>. A vector <span class="math inline"><em>u</em></span> is <em>orthogonal</em> to <span class="math inline"><em>S</em></span> if it is orthogonal to every vector in <span class="math inline"><em>S</em></span>. The set of all vectors orthogonal to <span class="math inline"><em>S</em></span> is called the <em>orthogonal complement</em> of <span class="math inline"><em>S</em></span> and is denoted <span class="math inline"><em>S</em><sup>⊥</sup></span>.</p>
<p>The orthogonal complement to a subspace is also a subspace.</p>
<p><strong>Theorem:</strong> Let <span class="math inline"><em>B</em> = {<em>v</em><sub>1</sub>, …, <em>v</em><sub><em>n</em></sub>}</span> be a basis for a subspace <span class="math inline"><em>S</em></span>. Then <span class="math inline"><em>u</em> ∈ <em>S</em><sup>⊥</sup></span> (<span class="math inline"><em>u</em></span> is orthogonal to <span class="math inline"><em>S</em></span>) if and only if <span class="math inline"><em>u</em></span> is orthogonal to each <span class="math inline"><em>v</em><sub><em>i</em></sub></span>.</p>
<p><strong>Example:</strong> Let <span class="math inline"><em>s</em><sub>1</sub> = (1, 0,  − 1)</span> and <span class="math inline"><em>s</em><sub>2</sub> = (1, 1, 1)</span> and <span class="math inline"><em>S</em></span> be the span of <span class="math inline"><em>s</em><sub>1</sub></span> and <span class="math inline"><em>s</em><sub>2</sub></span>. Is <span class="math inline"><em>u</em> = ( − 1, 1, 1) ∈ <em>S</em><sup>⊥</sup></span>? What is a basis for <span class="math inline"><em>S</em><sup>⊥</sup></span>?</p>
<p><strong>Definition:</strong> A set of vectors <span class="math inline"><em>V</em></span> in <span class="math inline">ℝ<sup><em>n</em></sup></span> form an <em>orthogonal set</em> the vectors are pairwise orthogonal. This means that if <span class="math inline"><em>v</em><sub><em>i</em></sub></span> and <span class="math inline"><em>v</em><sub><em>j</em></sub></span> are distinct vectors in <span class="math inline"><em>V</em></span>, then <span class="math inline"><em>v</em><sub><em>i</em></sub> ⋅ <em>v</em><sub><em>j</em></sub> = 0</span>.</p>
<p><strong>Example:</strong></p>
<ul>
<li>Is the standard basis an orthogonal set?</li>
<li>What’s a basis that is not orthogonal?</li>
</ul>
<p><strong>Theorem:</strong> An orthogonal set of nonzero vectors is linearly independent.</p>
<p><strong>Definition:</strong> A basis that is orthogonal as a set is called an <em>orthogonal basis</em>. A basis that is orthogonal as a set and is comprised of vectors of norm 1 is called an <em>orthonormal basis</em>.</p>
<p><strong>Theorem:</strong> Let <span class="math inline"><em>S</em></span> be a subspace with orthogonal basis <span class="math inline">{<em>v</em><sub>1</sub>, …, <em>v</em><sub><em>k</em></sub>}</span>. Then any vector <span class="math inline"><em>s</em> ∈ <em>S</em></span> can be written as a linear combination <span class="math inline"><em>v</em> = <em>c</em><sub>1</sub><em>v</em><sub>1</sub> + … + <em>c</em><sub><em>k</em></sub><em>v</em><sub><em>k</em></sub></span> with <span class="math inline"><em>c</em><sub><em>i</em></sub> = <em>v</em><sub><em>i</em></sub> ⋅ <em>s</em>/∥<em>v</em><sub><em>i</em></sub>∥<sup>2</sup></span>.</p>
<p><strong>Example:</strong> (THIS IS A BAD EXAMPLE. TURNS OUT NOT TO BE ORTHOGONAL.) Let <span class="math inline"><em>v</em><sub>1</sub> = ( − 2, 1, 1), <em>v</em><sub>2</sub> = (1,  − 1,  − 3), <em>v</em><sub>3</sub> = (4, 7,  − 1)</span>. Write <span class="math inline">(3,  − 1, 5)</span> as a linear combination of <span class="math inline"><em>v</em><sub><em>i</em></sub></span>.</p>
<p>For finite dimensional spaces, we have that <span class="math inline">(<em>S</em><sup>⊥</sup>)<sup>⊥</sup> = <em>S</em></span>. Use this to show that every subspace is the null space of some matrix.</p>
