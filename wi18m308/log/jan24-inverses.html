<h1 id="jan-24">Jan 24</h1>
<ul>
<li>Introduce nullspace and columns space</li>
<li>Draw picture of domain, range, kernel, codomain</li>
</ul>
<h3 id="theorem-related-to-linear-independence">Theorem related to linear independence</h3>
<p>Let <span class="math inline"><em>S</em> = {<em>a</em><sub>1</sub>, …, <em>a</em><sub><em>n</em></sub>} ⊆ ℝ<sup><em>m</em></sup></span> be a set of vectors. Let <span class="math inline"><em>A</em></span> be the <span class="math inline"><em>m</em> × <em>n</em></span> matrix formed by writing the elements of <span class="math inline"><em>S</em></span> as columns. Let <span class="math inline"><em>T</em> : ℝ<sup><em>n</em></sup> → ℝ<sup><em>m</em></sup></span> be the linear transformation defined by <span class="math inline"><em>T</em>(<em>x</em>) = <em>A</em><em>x</em></span>.</p>
<ul>
<li><span class="math inline"><em>S</em></span> is linearly independent</li>
<li><span class="math inline"><em>A</em><em>x</em> = 0</span> has only the trivial solution</li>
<li>For any <span class="math inline"><em>b</em></span>, <span class="math inline"><em>A</em><em>x</em> = <em>b</em></span> has either no solution or exactly one solution.</li>
<li><span class="math inline"><em>n</em><em>u</em><em>l</em><em>l</em>(<em>A</em>) = {0}</span></li>
<li><span class="math inline"><em>T</em></span> is one-to-one</li>
<li><span class="math inline"><em>k</em><em>e</em><em>r</em>(<em>T</em>) = {0}</span></li>
</ul>
<h3 id="theorem-related-to-spanning">Theorem related to spanning</h3>
<p>Let <span class="math inline"><em>S</em> = {<em>a</em><sub>1</sub>, …, <em>a</em><sub><em>n</em></sub>} ⊆ ℝ<sup><em>m</em></sup></span> be a set of vectors. Let <span class="math inline"><em>A</em></span> be the <span class="math inline"><em>m</em> × <em>n</em></span> matrix formed by writing the elements of <span class="math inline"><em>S</em></span> as columns. Let <span class="math inline"><em>T</em> : ℝ<sup><em>n</em></sup> → ℝ<sup><em>m</em></sup></span> be the linear transformation defined by <span class="math inline"><em>T</em>(<em>x</em>) = <em>A</em><em>x</em></span>.</p>
<ul>
<li><span class="math inline"><em>S</em></span> is spanning</li>
<li><span class="math inline"><em>A</em><em>x</em> = <em>b</em></span> has a solution for any <span class="math inline"><em>b</em></span></li>
<li><span class="math inline"><em>c</em><em>o</em><em>l</em>(<em>A</em>) = ℝ<sup><em>m</em></sup></span></li>
<li><span class="math inline"><em>T</em></span> is onto</li>
<li><span class="math inline"><em>r</em><em>a</em><em>n</em><em>g</em><em>e</em>(<em>T</em>) = ℝ<sup><em>m</em></sup></span></li>
</ul>
<h3 id="theorem-related-to-the-square-case">Theorem related to the square case</h3>
<p>Let <span class="math inline"><em>S</em> = {<em>a</em><sub>1</sub>, …, <em>a</em><sub><em>n</em></sub>} ⊆ ℝ<sup><em>n</em></sup></span> be a set of vectors. Let <span class="math inline"><em>A</em></span> be the <span class="math inline"><em>n</em> × <em>n</em></span> matrix formed by writing the elements of <span class="math inline"><em>S</em></span> as columns. Let <span class="math inline"><em>T</em> : ℝ<sup><em>n</em></sup> → ℝ<sup><em>n</em></sup></span> be the linear transformation defined by <span class="math inline"><em>T</em>(<em>x</em>) = <em>A</em><em>x</em></span>.</p>
<ul>
<li><span class="math inline"><em>S</em></span> is a basis</li>
<li><span class="math inline"><em>S</em></span> is linearly independent</li>
<li><span class="math inline"><em>S</em></span> is spanning</li>
<li><span class="math inline"><em>A</em><em>x</em> = <em>b</em></span> always has a unique solution</li>
<li><span class="math inline"><em>c</em><em>o</em><em>l</em>(<em>A</em>) = ℝ<sup><em>n</em></sup></span></li>
<li><span class="math inline"><em>n</em><em>u</em><em>l</em><em>l</em>(<em>A</em>) = ℝ<sup><em>n</em></sup></span></li>
<li><span class="math inline"><em>T</em></span> is invertible</li>
<li><span class="math inline"><em>A</em></span> is invertible</li>
</ul>
<h2 id="matrix-algebra">3.2 Matrix Algebra</h2>
<h3 id="matrix-multiplication-is-weird">Matrix multiplication is weird</h3>
<ul>
<li><span class="math inline"><em>A</em><em>B</em> ≠ <em>B</em><em>A</em></span></li>
<li>Explain what <span class="math inline"><em>A</em><em>B</em> = 0</span> means in terms of columnspace and nullspace</li>
</ul>
<h3 id="tranpose-of-a-matrix">Tranpose of a matrix</h3>
<ul>
<li>Teach how to tranpose</li>
<li><span class="math inline">(<em>A</em> + <em>B</em>)<sup><em>t</em></sup> = <em>A</em><sup><em>t</em></sup> + <em>B</em><sup><em>t</em></sup></span></li>
<li><span class="math inline">(<em>s</em><em>A</em>)<sup><em>t</em></sup></span></li>
<li><span class="math inline">(<em>A</em><em>C</em>)<sup><em>t</em></sup> = <em>C</em><sup><em>t</em></sup><em>A</em><sup><em>t</em></sup></span></li>
</ul>
<h3 id="diagonal-matrices-and-upper-triangular-matrices-is-a-thing">Diagonal matrices and upper triangular matrices is a thing</h3>
<ul>
<li>Give definition</li>
<li>The product of digaonl is diagonal. Discuss the effects of multiplying a matrice by a diagonal matrix</li>
<li>The product of upper triangulars is upper triangular</li>
</ul>
<h3 id="powers-of-matrices-is-a-thing">Powers of matrices is a thing</h3>
<ul>
<li>Powers of diagonal is easy</li>
<li>Wouldn’t it be great if <span class="math inline"><em>A</em> = <em>U</em><em>D</em><em>U</em><sup> − 1</sup></span></li>
</ul>
<h2 id="inverses">3.3 Inverses</h2>
<ul>
<li>Explain what an inverse is.</li>
<li>Derive inverse formula.</li>
</ul>
